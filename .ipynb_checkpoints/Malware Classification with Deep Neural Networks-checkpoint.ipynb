{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWAMI KARUPPASWAMI THUNNAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanchana\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AbortDoc</th>\n",
       "      <th>AbortPath</th>\n",
       "      <th>ActivateKeyboardLayout</th>\n",
       "      <th>AddAce</th>\n",
       "      <th>AddAtomA</th>\n",
       "      <th>AddAtomW</th>\n",
       "      <th>AddFontMemResourceEx</th>\n",
       "      <th>AddFontResourceA</th>\n",
       "      <th>AddFontResourceExW</th>\n",
       "      <th>AddFontResourceW</th>\n",
       "      <th>...</th>\n",
       "      <th>lstrlenW</th>\n",
       "      <th>mciSendCommandA</th>\n",
       "      <th>sndPlaySoundA</th>\n",
       "      <th>timeKillEvent</th>\n",
       "      <th>timeSetEvent</th>\n",
       "      <th>wsprintfA</th>\n",
       "      <th>wsprintfW</th>\n",
       "      <th>wvsprintfA</th>\n",
       "      <th>wvsprintfW</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1729 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AbortDoc  AbortPath  ActivateKeyboardLayout  AddAce  AddAtomA  AddAtomW  \\\n",
       "0         0          0                       0       0         0         0   \n",
       "1         0          0                       0       0         0         0   \n",
       "2         0          0                       0       0         0         0   \n",
       "3         0          0                       0       0         0         0   \n",
       "4         0          0                       0       0         0         0   \n",
       "\n",
       "   AddFontMemResourceEx  AddFontResourceA  AddFontResourceExW  \\\n",
       "0                     0                 0                   0   \n",
       "1                     0                 0                   0   \n",
       "2                     0                 0                   0   \n",
       "3                     0                 0                   0   \n",
       "4                     0                 0                   0   \n",
       "\n",
       "   AddFontResourceW   ...    lstrlenW  mciSendCommandA  sndPlaySoundA  \\\n",
       "0                 0   ...           0                0              0   \n",
       "1                 0   ...           0                0              0   \n",
       "2                 0   ...           0                0              0   \n",
       "3                 0   ...           1                0              0   \n",
       "4                 0   ...           0                0              0   \n",
       "\n",
       "   timeKillEvent  timeSetEvent  wsprintfA  wsprintfW  wvsprintfA  wvsprintfW  \\\n",
       "0              0             0          1          0           0           0   \n",
       "1              0             0          1          0           0           0   \n",
       "2              0             0          0          0           0           0   \n",
       "3              0             0          0          0           0           0   \n",
       "4              0             0          0          0           0           0   \n",
       "\n",
       "   RESULT  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 1729 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us have a look at the head of our dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get independent and dependent variables\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe our model\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanchana\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=1728, units=500, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Kanchana\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=250)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Kanchana\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=7)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Add our layers\n",
    "classifier.add(Dense(output_dim=750, init=\"uniform\", activation=\"relu\", input_dim=1728))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(output_dim=500, activation=\"relu\"))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(output_dim=250, activation=\"relu\"))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(output_dim=7, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 1.6283 - acc: 0.4060\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0474 - acc: 0.6466\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.8636 - acc: 0.6767\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.7138 - acc: 0.7519\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6521 - acc: 0.7218\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6255 - acc: 0.7218\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5872 - acc: 0.7293\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5878 - acc: 0.7293\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5626 - acc: 0.7293\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5615 - acc: 0.7218\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5733 - acc: 0.7368\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5732 - acc: 0.6842\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5536 - acc: 0.7068\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5534 - acc: 0.6767\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5521 - acc: 0.6917\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5462 - acc: 0.7444\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5430 - acc: 0.7293\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5490 - acc: 0.7068\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5514 - acc: 0.7368\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5419 - acc: 0.7368\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5620 - acc: 0.7218\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5442 - acc: 0.7368\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5680 - acc: 0.7368\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5464 - acc: 0.7368\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5431 - acc: 0.7293\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5419 - acc: 0.7068\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5447 - acc: 0.7293\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5445 - acc: 0.6917\n",
      "Epoch 29/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5461 - acc: 0.7143\n",
      "Epoch 30/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5487 - acc: 0.7368\n",
      "Epoch 31/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5426 - acc: 0.7143\n",
      "Epoch 32/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5496 - acc: 0.7218\n",
      "Epoch 33/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5368 - acc: 0.7444\n",
      "Epoch 34/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5418 - acc: 0.7293\n",
      "Epoch 35/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5416 - acc: 0.7068\n",
      "Epoch 36/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5396 - acc: 0.7218\n",
      "Epoch 37/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5385 - acc: 0.7293\n",
      "Epoch 38/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5438 - acc: 0.7293\n",
      "Epoch 39/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5470 - acc: 0.7368\n",
      "Epoch 40/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5452 - acc: 0.7143\n",
      "Epoch 41/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5416 - acc: 0.7293\n",
      "Epoch 42/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5403 - acc: 0.7444\n",
      "Epoch 43/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5551 - acc: 0.7368\n",
      "Epoch 44/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5435 - acc: 0.7368\n",
      "Epoch 45/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5443 - acc: 0.7368\n",
      "Epoch 46/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5475 - acc: 0.7293\n",
      "Epoch 47/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.7293\n",
      "Epoch 48/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5520 - acc: 0.6992\n",
      "Epoch 49/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5385 - acc: 0.7293\n",
      "Epoch 50/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5384 - acc: 0.7143\n",
      "Epoch 51/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5385 - acc: 0.7218\n",
      "Epoch 52/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5400 - acc: 0.7368\n",
      "Epoch 53/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5403 - acc: 0.7293\n",
      "Epoch 54/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5383 - acc: 0.7293\n",
      "Epoch 55/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5391 - acc: 0.7368\n",
      "Epoch 56/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5357 - acc: 0.7218\n",
      "Epoch 57/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5348 - acc: 0.7068\n",
      "Epoch 58/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5395 - acc: 0.7293\n",
      "Epoch 59/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5376 - acc: 0.7293\n",
      "Epoch 60/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5394 - acc: 0.7368\n",
      "Epoch 61/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5377 - acc: 0.7293\n",
      "Epoch 62/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5392 - acc: 0.7444\n",
      "Epoch 63/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5400 - acc: 0.7444\n",
      "Epoch 64/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5409 - acc: 0.7143\n",
      "Epoch 65/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5379 - acc: 0.7293\n",
      "Epoch 66/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5429 - acc: 0.7293\n",
      "Epoch 67/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5387 - acc: 0.7068\n",
      "Epoch 68/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5477 - acc: 0.6992\n",
      "Epoch 69/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5354 - acc: 0.7218\n",
      "Epoch 70/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5460 - acc: 0.7293\n",
      "Epoch 71/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5392 - acc: 0.7293\n",
      "Epoch 72/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5364 - acc: 0.7368\n",
      "Epoch 73/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5376 - acc: 0.7368\n",
      "Epoch 74/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5349 - acc: 0.7068\n",
      "Epoch 75/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5447 - acc: 0.7293\n",
      "Epoch 76/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5392 - acc: 0.7444\n",
      "Epoch 77/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5449 - acc: 0.6992\n",
      "Epoch 78/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5430 - acc: 0.7293\n",
      "Epoch 79/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5397 - acc: 0.7143\n",
      "Epoch 80/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5395 - acc: 0.7444\n",
      "Epoch 81/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5393 - acc: 0.7368\n",
      "Epoch 82/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5358 - acc: 0.7293\n",
      "Epoch 83/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5406 - acc: 0.7293\n",
      "Epoch 84/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5420 - acc: 0.7368\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5460 - acc: 0.7218\n",
      "Epoch 86/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5364 - acc: 0.7068\n",
      "Epoch 87/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5375 - acc: 0.7368\n",
      "Epoch 88/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5379 - acc: 0.7143\n",
      "Epoch 89/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5378 - acc: 0.7293\n",
      "Epoch 90/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5434 - acc: 0.7444\n",
      "Epoch 91/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5398 - acc: 0.7293\n",
      "Epoch 92/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5379 - acc: 0.7368\n",
      "Epoch 93/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5440 - acc: 0.7293\n",
      "Epoch 94/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5399 - acc: 0.7368\n",
      "Epoch 95/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5406 - acc: 0.7068\n",
      "Epoch 96/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5357 - acc: 0.7444\n",
      "Epoch 97/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5429 - acc: 0.7293\n",
      "Epoch 98/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5427 - acc: 0.7444\n",
      "Epoch 99/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5424 - acc: 0.7444\n",
      "Epoch 100/100\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5347 - acc: 0.7444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2189093db00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X, y, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
